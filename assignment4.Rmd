---
title: "Assignment 4"
author: "Rory Sarten 301005654"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    pandoc_args: "--highlight-style=breezeDark"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
library(magrittr)
```

## Question 1

a)

```{r Q1_a}
food_prices <- readr::read_delim("food_prices_kg2019.csv", delim = ",", col_types = readr::cols())
theta_est <- IQR(food_prices$Data_value) %>% round(3)
theta_est
```

b)

```{r Q1_b}
set.seed(1)
N <- 1e4
boot_IQR <- 1:N %>% 
  lapply(function(i) sample(food_prices$Data_value, replace = TRUE)) %>% 
  sapply(IQR) %>% 
  round(3)

## standard error of estimator
sd(boot_IQR) %>% round(3)

## standard 95% bootstrap confidence interval
(theta_est + 1.96*c(-1, 1)*sd(boot_IQR)) %>% round(3)
```

c)

```{r Q1_c}
## Efron's interval
quantile(boot_IQR, probs = c(0.025, 0.975)) %>% round(3)
```

d)

```{r Q1_d}
## Hall's interval
hall <- (2 * theta_est - quantile(boot_IQR, probs = c(0.975, 0.025))) %>% round(3)
names(hall) <- c("2.5%", "97.5%")
hall
```

e)

```{r Q1_e}
## bias
bias <- (mean(boot_IQR) - theta_est) %>% round(3)
bias

## size of bias in relation to the std error
bias_size <- (bias/sd(boot_IQR)) %>% round(3)
bias_size
```

The bias is approximately `r round(bias_size * 100, digits = 0)`% of the $s.e.(\hat\theta)$. The size of this bias is considerable.

f)

```{r Q1_f}
## bias corrected Efron interval
(quantile(boot_IQR, probs = c(0.025, 0.975)) - bias) %>% round(3)
```

The lower bound of the confidence interval is above $4. We reject the hypothesis that the test IQR could be below 4NZD at the 5% confidenc interval.

## Question 2

a)

1. Calculate the observed $\hat\beta$ and $\hat\sigma^2$ from the observed data
2. Draw a sample of the observations with replacement and calculate a new estimate $\hat\beta^*_b$ from the sample
3. Repeat step 2 $N$ times
4. Calculate $s.e.(\hat\beta^*)$ as the standard error over the results of the bootstrapped samples
5. Calculate $\hat\beta \pm1.96\times s.e.(\hat\beta^*)$ (for 95% confidence interval)

b)

```{r Q2_b}
galaxy <- readr::read_delim("galaxies.csv", delim = ",", col_types = readr::cols())
velocity <- galaxy$v %>% as.numeric()
galaxy$d <- as.numeric(galaxy$d)
distance <- galaxy$d

############################################
## Calculations
calc_beta <- function(v, d) sum(v)/sum(d)

calc_sigma <- function(v, d) {
  beta_est <- calc_beta(v, d)
  mean(1/d*(v - beta_est*d)^2)
}
############################################

n <- length(distance)
beta_est <- calc_beta(velocity, distance)
sigma_est <- calc_sigma(velocity, distance)

N <- 1e4
set.seed(1)
bootstrap_velocity <- 1:N %>% 
  lapply(function(i) {
    beta_est*distance + rnorm(n, sd = sqrt(sigma_est * distance))})

bootstrap_beta <- bootstrap_velocity %>% 
  sapply(calc_beta, distance)

estimate <- mean(bootstrap_beta)
ci <- beta_est + 1.96 * c(-1, 1) * sd(bootstrap_beta)

results <- c(estimate, ci) %>% round(3)
names(results) <- c("Estimate", "Lower", "Upper")
results

## Reserve results for part d)
bootstrap_sigma2 <- bootstrap_velocity %>% 
  sapply(calc_sigma, distance)
bootstrap_sigma2_est <- mean(bootstrap_sigma2)
ci <- sigma_est + 1.96 * c(-1, 1) * sd(bootstrap_sigma2)
sigma2_results <- c(bootstrap_sigma2_est, ci)
bootstrap_results <- rbind(results, sigma2_results)
rownames(bootstrap_results) <- c("Beta", "Sigma2")
```

Using the boot package

```{r Q2_b_bootpackage}
boot_beta <- function(dataset, beta_est, sigma_est) {
  v <- beta_est*dataset$d + rnorm(n, sd = sqrt(sigma_est * dataset$d))
  calc_beta(v, dataset$d)
}

library(boot)
set.seed(1)
boot_stats <- boot(galaxy,
                   sim = "parametric",
                   statistic = boot_beta,
                   R = N,
                   beta_est = beta_est,
                   sigma_est = sigma_est)

boot_stats_se <- boot_stats$t %>% sd() %>% round(3)

estimate <- mean(boot_stats$t)
ci <- beta_est + 1.96 * c(-1, 1) * boot_stats_se

boot_results <- c(estimate, ci) %>% round(3)
names(boot_results) <- c("Estimate", "Lower", "Upper")
boot_results
```

c)

$y_i\sim N(\beta x_i, \sigma^2 x_i)$

$\begin{aligned}L(\beta, \sigma | \boldsymbol{y}) =& \prod\limits_{i=1}^n \left[ (2\pi\sigma^2x_i)^{1/2} \exp(-\dfrac{(y_i - \beta x_i)^2}{2\sigma^2x_i}) \right] \\ \ell = & -\dfrac{1}{n} \sum\limits_{i=1}^n\log(2\pi \sigma^2) -\dfrac{1}{n} \sum\limits_{i=1}^n\log(x_i) - \dfrac{1}{2\sigma^2} \sum\limits_{i=1}^nx_i^{-1}(y_i-\beta x_i)^2 \\ \end{aligned}$

Solving for $\hat\beta$ we only need the last term.

$\begin{aligned} \dfrac{\partial\ell}{\partial\beta} = & \dfrac{1}{\sigma^2}\sum\limits_{i=1}^n(y_i-\beta x_i)\quad \text{setting equal to 0} \\ \dfrac{1}{\sigma^2}\sum\limits_{i=1}^ny_i = & \beta \dfrac{1}{\sigma^2}\sum\limits_{i=1}^nx_i \\ \beta =& \dfrac{\sum_{i=1}^ny_i}{\sum_{i=1}^nx_i} \\ \hat\beta =& \dfrac{\bar{y}}{\bar{x}}  \end{aligned}$

Solving for $\hat\sigma^2$

$\begin{aligned} \dfrac{\partial\ell}{\partial\sigma^2} = & -\dfrac{n}{2\sigma^2} + \dfrac{1}{2\sigma^4}\sum\limits_{i=1}^nx_i^{-1}(y_i-\beta x_i)^2 \quad \text{setting equal to 0} \\ \dfrac{n}{2\sigma^2} =& \dfrac{1}{2\sigma^4}\sum\limits_{i=1}^nx_i^{-1}(y_i-\beta x_i)^2 \\ \dfrac{2\sigma^4}{2\sigma^2} = & \dfrac{1}{n}\sum\limits_{i=1}^nx_i^{-1}(y_i-\beta x_i)^2 \\ \hat\sigma^2 =& \dfrac{1}{n}\sum\limits_{i=1}^n \dfrac{1}{x_i}(y_i-\beta x_i)^2  \end{aligned}$

d)

```{r Q2_d}
loglikelihood <- function(params, x, y) {
  n <- length(x)
  beta_ <- params[1]
  sigma2_ <- params[2]
  -(n/2)*log(2*pi*sigma2_) - 0.5 * sum(log(x)) - (1/(2*sigma2_)) * sum((y - beta_*x)^2 / x)
}

result <- optim(par = c(40, 250),
                fn = loglikelihood,
                x = distance, y = velocity,
                lower = c(0, 250), upper = c(Inf, Inf),
                method = "L-BFGS-B",
                control = list(fnscale = -1),
                hessian = TRUE)

opt_mle_se <- solve(-result$hessian) %>% diag() %>% sqrt() %>% round(3)
ci <- result$par[1] + c(-1, 1) * 1.96 * opt_mle_se[1]
likelihood_beta_results <- c(result$par[1], ci) %>% round(3)
names(likelihood_beta_results) <- c("Estimate", "Lower", "Upper")
#likelihood_beta_results

ci <- result$par[2] + c(-1, 1) * 1.96 * opt_mle_se[2]
likelihood_sigma_results <- c(result$par[2], ci) %>% round(3)
names(likelihood_sigma_results) <- c("Estimate", "Lower", "Upper")
#likelihood_sigma_results

output <- rbind(likelihood_beta_results, likelihood_sigma_results)
rownames(output) <- c("Beta", "Sigma2")
#output
```


```{r Q2_d_results}
knitr::kable(bootstrap_results, caption = "Bootstrap Estimates")
knitr::kable(output, caption = "optim Estimates")
```

The estimates for $\hat\beta$ are very similar. The 95% confidence interval widths are `r bootstrap_results[5] - bootstrap_results[3]` and `r output[5] - output[3]`

The estimates for $\hat\sigma^2$ are more divergent. The 95% confidence interval widths are `r round(bootstrap_results[6] - bootstrap_results[4], 1)` and `r round(output[6] - output[4], 1)`. This is not surprising as the log-likelihood function is not symmetric around the test statistic.

## Question 3

a)

